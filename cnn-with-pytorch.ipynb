{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abhayratti/cnn-with-pytorch?scriptVersionId=111696210\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-21T23:14:02.83545Z","iopub.execute_input":"2022-11-21T23:14:02.835858Z","iopub.status.idle":"2022-11-21T23:14:02.842661Z","shell.execute_reply.started":"2022-11-21T23:14:02.835823Z","shell.execute_reply":"2022-11-21T23:14:02.84105Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nnum_classes = 10\nlearning_rate = 0.001\nnum_epochs = 20\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T23:13:25.283947Z","iopub.execute_input":"2022-11-21T23:13:25.284465Z","iopub.status.idle":"2022-11-21T23:13:25.292552Z","shell.execute_reply.started":"2022-11-21T23:13:25.284421Z","shell.execute_reply":"2022-11-21T23:13:25.290229Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"all_transforms = transforms.Compose([transforms.Resize((32,32)), \n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], \n                                                        std =[0.2023, 0.1994, 0.2010])\\\n                                    ])\n\ntrain_dataset = torchvision.datasets.CIFAR10(root = \"./data\",\n                                            train = True,\n                                            transform = all_transforms,\n                                            download = True)\n\ntest_dataset = torchvision.datasets.CIFAR10(root = \"./data\",\n                                           train = False,\n                                           transform = all_transforms,\n                                           download = True)\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                          batch_size = batch_size,\n                                          shuffle = True)\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                         batch_size = batch_size,\n                                         shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T23:38:39.61782Z","iopub.execute_input":"2022-11-21T23:38:39.618393Z","iopub.status.idle":"2022-11-21T23:38:41.109859Z","shell.execute_reply.started":"2022-11-21T23:38:39.618302Z","shell.execute_reply":"2022-11-21T23:38:41.108496Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"class ConvNeuralNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ConvNeuralNet, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.fc1 = nn.Linear(1600, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, num_classes)\n    \n    def forward(self, x):\n        out = self.conv_layer1(x)\n        out = self.conv_layer2(out)\n        out = self.max_pool1(out)\n        \n        out = self.conv_layer3(out)\n        out = self.conv_layer4(out)\n        out = self.max_pool2(out)\n        \n        out = out.reshape(out.size(0), -1)\n        \n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-11-21T23:53:58.007669Z","iopub.execute_input":"2022-11-21T23:53:58.008113Z","iopub.status.idle":"2022-11-21T23:53:58.019578Z","shell.execute_reply.started":"2022-11-21T23:53:58.008075Z","shell.execute_reply":"2022-11-21T23:53:58.017895Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = ConvNeuralNet(num_classes)\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n\ntotal_step = len(train_loader)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T00:41:23.829392Z","iopub.execute_input":"2022-11-22T00:41:23.829786Z","iopub.status.idle":"2022-11-22T00:41:23.843682Z","shell.execute_reply.started":"2022-11-22T00:41:23.829749Z","shell.execute_reply":"2022-11-22T00:41:23.84195Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2022-11-22T00:43:42.261657Z","iopub.execute_input":"2022-11-22T00:43:42.262068Z","iopub.status.idle":"2022-11-22T01:02:57.604525Z","shell.execute_reply.started":"2022-11-22T00:43:42.262033Z","shell.execute_reply":"2022-11-22T01:02:57.602946Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch [1/20], Loss: 1.7742\nEpoch [2/20], Loss: 1.4596\nEpoch [3/20], Loss: 0.8846\nEpoch [4/20], Loss: 1.0588\nEpoch [5/20], Loss: 1.1241\nEpoch [6/20], Loss: 1.0226\nEpoch [7/20], Loss: 0.8822\nEpoch [8/20], Loss: 1.0253\nEpoch [9/20], Loss: 1.1013\nEpoch [10/20], Loss: 0.6995\nEpoch [11/20], Loss: 0.9861\nEpoch [12/20], Loss: 0.6343\nEpoch [13/20], Loss: 0.5414\nEpoch [14/20], Loss: 0.8114\nEpoch [15/20], Loss: 0.6785\nEpoch [16/20], Loss: 0.2784\nEpoch [17/20], Loss: 0.9813\nEpoch [18/20], Loss: 0.7905\nEpoch [19/20], Loss: 0.6194\nEpoch [20/20], Loss: 0.5405\n","output_type":"stream"}]},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels, in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n    print('Acurracy on {} train images: {}%'.format(50000, 100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2022-11-22T01:06:13.740413Z","iopub.execute_input":"2022-11-22T01:06:13.740834Z","iopub.status.idle":"2022-11-22T01:06:42.951356Z","shell.execute_reply.started":"2022-11-22T01:06:13.740797Z","shell.execute_reply":"2022-11-22T01:06:42.949944Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Acurracy on 50000 train images: 82.804%\n","output_type":"stream"}]}]}